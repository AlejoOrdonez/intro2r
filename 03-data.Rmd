# Data in R {#data_r}

Until now, you've created fairly simple data in R and stored it in a [vector](#funcs). However, most (if not all) of you will have much more complicated datasets from your various experiments and surveys that go well beyond what a vector can handle. Learning how R deals with different types of data and data structures, how to import your data into R and how to manipulate and summarise your data are some of the most important skills you will need to master. 

In this Chapter we'll go over the main data types in R and focus on some of the most common data structures. We will also cover how to import data into R from an external file, how to manipulate and summarise (wrangle) data and finally how to export data from R to an external file.

## Data types

Understanding the different types of data and how R deals with these data is important. The temptation is to glaze over and skip these technical details, but beware, this can come back to bite you somewhere unpleasant if you don't pay attention. We've already seen an [example](#r_objs) of this when we tried (and failed) to add two character objects together using the `+` operator.

R has six basic types of data; numeric, integer, logical, complex and character. The keen eyed among you will notice we've only listed five data types here, the final data type is raw which we won't cover as it's not useful 99.999% of the time. We also won't cover complex numbers as we don't have the [imagination][complex_num]!

\  

  - **Numeric** data are numbers that contain a decimal. Actually they can also be whole numbers but we'll gloss over that.

  - **Integers** are whole numbers (those numbers without a decimal point).

  - **Logical** data take on the value of either `TRUE` or `FALSE`. There's also another special type of logical called `NA` to represent missing values.

  - **Character** data are used to represent string values. You can think of strings as something like a word or (multiple words). A special type of character string is a *factor*, which is a character string but with additional attributes (like levels or an order). We'll cover factors later. 

\  

R is (usually) able to automatically distinguish between different classes of data by their nature and the context in which they're used although you should bear in mind that R can't actually read your mind and you may have to explicitly tell R how you want to treat a data type. You can find out the type (or class) of any object using the `class()` function.

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
num <- 2.2
class(num)

char <- "hello"
class(char)

logi <- TRUE
class(logi)

```

Alternatively, you can ask if an object is a specific class using using a logical test. The `is.[typeOfData]()` family of functions will return either a `TRUE` or a `FALSE`.

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
is.numeric(num)

is.character(num)

is.character(char)

is.logical(logi)

```

It can sometimes be useful to be able to change the class of a variable using the `as.[className]()` family of coercion functions, although you need to be careful when doing this as you might receive some unexpected results.

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
# coerce numeric to character
class(num)
num_char <-  as.character(num)
num_char
class(num_char)

# coerce character to numeric!
class(char)
char_num <- as.numeric(char)

```

Here's a summary table of some of the logical test and coercion functions available to you.

|     Type       |    Logical test       |     Coercing       |
|:--------------:|:-------------------:|:-----------------:|
|  Character     |   `is.character`   |   `as.character`   |
|  Numeric   |   `is.numeric`   |   `as.numeric`   |
|  Logical | `is.logical` | `as.logical` |
|  Factor   |   `is.factor`  |   `as.factor`  |
|  Complex     |   `is.complex`    |   `as.complex`    |

## Data structures

Now that you've been introduced to some of the most important classes of data in R, letâ€™s have a look at some of main structures that we have for storing these data. 

### Scalars and vectors {#vectors}

Perhaps the simplest type of data structure is the vector. You've already been introduced to vectors in [Chapter 2](#funcs) although some of the vectors you created only contained a single value. Vectors that have a single value (length 1) are called scalars. Vectors can contain numbers, characters, factors or logicals, but the key thing to remember is that all the elements inside a vector must be of the same class. In other words, vectors can contain either numbers, characters or logicals but not mixtures of these types of data. There is one important exception to this, you can include `NA` (remember this is special type of logical) to denote missing data in vectors with other data types. 

\  

```{r data_struc, echo=FALSE, out.width="40%", fig.align="center"}
knitr::include_graphics(path = "images/scal_vec.png")
```

### Matrices and arrays

Another useful data structure used in many disciplines such as population ecology, theoretical and applied statistics is the matrix. A matrix is simply a vector that has additional attributes called dimensions. Arrays are just multidimensional matrices. Again, matrices and arrays must contain elements all of the same data class.

\  

```{r data_struc2, echo=FALSE, out.width="50%", fig.align="center"}
knitr::include_graphics(path = "images/mat_array.png")
```

\ 

A convenient way to create a matrix or an array is to use the `matrix()` and `array()` functions respectively. Below, we will create a matrix from a sequence 1 to 16 in four rows (`nrow = 4`) and fill the matrix row-wise (`byrow = TRUE`) rather than the default column-wise. When using the `array()` function we define the dimensions using the `dim =` argument, in our case 2 rows, 4 columns in 2 different matrices.   

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
my_mat <- matrix(1:16, nrow = 4, byrow = TRUE)
my_mat

my_array <- array(1:16, dim = c(2, 4, 2))
my_array
```

Sometimes it's also useful to define row and column names for your matrix but this is not a requirement. To do this use the `rownames()` and `colnames()` functions.

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
rownames(my_mat) <- c("A", "B", "C", "D")
colnames(my_mat) <- c("a", "b", "c", "d")
my_mat
```

Once you've created your matrices you can do useful stuff with them and as you'd expect, R has numerous built in functions to perform matrix operations. Some of the most common are given below. For example, to transpose a matrix we use the transposition function `t()`

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
my_mat_t <- t(my_mat)
my_mat_t
```

To extract the diagonal elements of a matrix and store them as a vector we can use the `diag()` function

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
my_mat_diag <- diag(my_mat)
my_mat_diag
```

The usual matrix addition, multiplication etc can be performed. Note the use of the `%*%` operator to perform matrix multiplication.

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
mat.1 <- matrix(c(2, 0, 1, 1), nrow = 2)	# notice that the matrix has been filled 
mat.1                                       # column-wise by default

mat.2 <- matrix(c(1, 1, 0, 2), nrow = 2)
mat.2

mat.1 + mat.2			# matrix addition
mat.1 * mat.2			# element by element products
mat.1 %*% mat.2			# matrix multiplication

```

### Data frames {#df}

By far the most commonly used data structure to store data in is the data frame. A data frame is a powerful two-dimensional object made up of rows and columns which looks superficially very similar to a matrix. However, whilst matrices are restricted to containing data all of the same type, data frames can contain a mixture of different types of data. Typically, in a data frame each row corresponds to an individual observation and each column corresponds to a different measured or recorded variable. This setup may be familiar to those of you who use LibreOffice Calc or Microsoft Excel to manage and store your data. Perhaps a useful way to think about data frames is that they are essentially made up of a bunch of vectors (columns) with each vector containing its own data type but the data type can be different between vectors. 

As an example, the data frame below contains the results of an experiment to determine the effect of removing the tip of petunia plants (*Petunia sp.*) grown at 3 levels of nitrogen on various measures of growth (note: data shown below are a subset of the full dataset). The data frame has 8 variables (columns) and each row represents an individual plant. The variables `tip treatment` and `nitrogen level` are factors ([categorical][cat-var] variables). The `tip treatment` variable has 2 levels (`tip` and `notip`) and the `nitrogen level` variable has 3 levels (`low`, `medium` and `high`). The variables `height`, `weight`, `leafarea` and `shootarea` are numeric and the variable `flowers` is an integer representing the number of flowers. Although the variable `block` has numeric values, these do not really have any order and could also be treated as a factor (i.e. they could also have been called A and B).

\  

```{r import-data, echo=FALSE, collapse=TRUE}
flowers <- read.table('data/flower.txt', header = TRUE)
knitr::kable(rbind(head(flowers), tail(flowers)), row.names = FALSE)
```

\  

There are a couple of important things to bear in mind about data frames. These types of objects are known as rectangular data (or tidy data) as each column must have the same number of observations. Also, any missing data should be recorded as an `NA` just as we did with our vectors. 

We can construct a data frame from existing data objects such as vectors using the `data.frame()` function. As an example, let's create three vectors `height`, `weight` and `p.names` and include all of these vectors in a data frame object called `dataf`.

```{r dataf, echo=TRUE, collapse=TRUE}
height <- c(180, 155, 160, 167, 181)
weight <- c(65, 50, 52, 58, 70)
p.names <- c("Joanna", "Charlotte", "Helen", "Karen", "Amy")

dataf <- data.frame(height = height, weight = weight, names = p.names)
dataf
```

You'll notice that each of the columns are named with variable name we supplied when we used the `data.frame` function. It also looks like the first column of the data frame is a series of numbers from one to five. Actually, this is not really a column but the name of each row. We can check this out by getting R to return the dimensions of the `dataf` object using the `dim()` function. We see that there are 5 rows and 3 columns.

```{r dataf2, echo=TRUE, collapse=TRUE}
dim(dataf)   # 5 rows and 3 columns
```

Another really useful function which we use all the time is `str()` which will return a compact summary of the structure of the data frame object (or any object for that matter).

```{r dataf3, echo=TRUE, collapse=TRUE}
str(dataf)   
```

The `str()` function gives us the data frame dimensions and also reminds us that `dataf` is a `data.frame` type object. It also lists all of the variables (columns) contained in the data frame, tells us what type of data the variables contain and prints out the first five values. We often copy this summary and place it in our R scripts with comments at the beginning of each line so we can easily refer back to it whilst writing our code. We showed you haw to comment blocks in RStudio [here](#proj_doc). 

Also notice that R has automatically decided that our `p.names` variable should be a factor when we first created the data frame. Whether this is a good idea or not will depend on how you want to use this variable in later analysis. If we decide that this wasn't such a good idea we can change the default behaviour of the `data.frame()` function by including the argument `stringsAsFactors = FALSE`. Now our strings are not automatically converted to factors and remain as characters (`chr`). 

```{r dataf4, echo=TRUE, collapse=TRUE}
height <- c(180, 155, 160, 167, 181)
weight <- c(65, 50, 52, 58, 70)
p.names <- c("Joanna", "Charlotte", "Helen", "Karen", "Amy")

dataf <- data.frame(height = height, weight = weight, names = p.names, 
										stringsAsFactors = FALSE)
str(dataf)
```

\  

## Importing data

Although creating data frames from existing data structures is extremely useful, by far the most common approach is to create a data frame by importing data from an external file. To do this, you'll need to have your data formatted correctly and saved in a file format that R is able to recognise. Fortunately for us, R is able to recognise a wide variety of file formats, although in reality you will probably end up using two or three regularly. 

### Saving files to import

Arguably, the easiest method of creating a data file to import into R is to enter your data into a spreadsheet using either Microsoft Excel or LibreOffice Calc and save the spreadsheet as a tab delimited file. We prefer LibreOffice Calc as it's open source, platform independent and free but MS Excel is OK too (but see [here][excel_gotcha] for some gotchas). For those of you unfamiliar with the tab delimited file format it simply means that data in different columns are separated with a 'tab' character (yes, the same one as on your keyboard) which is usually saved as a file with a '.txt' extension (you might also see `.tsv` which is short for tab separated values).

To save a spreadsheet as a tab delimited file in LibreOffice Calc select `File` -> `Save as ...` from the main menu and specify the location you wish to save your file in the 'Save in folder' option and the name of the file in the 'Name' option. In the drop down menu located above the 'Save' button change the default  'All formats' to 'Text CSV (.csv)'.

\  

```{r LO-calc, echo=FALSE, out.width="60%", fig.align="center"}
knitr::include_graphics(path = "images/libre_off1.png")
```

\  

Click the Save button and then select the 'Use Text CSV Format' option. In the next pop-up window select `{Tab}` from the drop down menu in the 'Field delimiter' option. Click on OK to save the file. 

\  

```{r LO-calc2, echo=FALSE, out.width="40%", fig.align="center"}
knitr::include_graphics(path = "images/libre_off2.png")
```

\  

The resulting file will annoyingly have a '.csv' extension even though we've saved it as a tab delimited file. Either live with it or rename the file with a '.txt' extension instead.

In MS Excel, select `File` -> `Save as ...` from the main menu and navigate to the folder where you want to save the file. Enter the file name (keep it fairly short, [no spaces](#file_names)!) in the 'Save as:' dialogue box. In the 'File format:' dialogue box click on the down arrow to open the drop down menu and select 'Text (Tab delimited)' as your file type. Select OK to save the file.

\  

```{r ms-excel, echo=FALSE, out.width="60%", fig.align="center"}
knitr::include_graphics(path = "images/ms_excel1.png")
```

\ 

There are a couple of things to bear in mind when saving files to import into R which will make your life easier in the long run. Keep your column headings (if you have them) short and informative. Also avoid spaces in your column headings by replacing them with an underscore or a dot (i.e. replace `shoot height` with `shoot_height` or `shoot.height`) and avoid using special characters (i.e. `leaf area (mm^2)`). Remember, if you have missing data in your data frame (i.e. empty cells) you should use an `NA` to represent these missing values. This will keep the data frame tidy. 

### Import functions

Once you've saved your data file in a suitable format we can now read this file into R. The workhorse function for importing data into R is the `read.table()` function (we discuss some alternatives later in the chapter). The `read.table()` function is a very flexible function with a shed load of arguments (see `?read.table`) but it's quite simple to use. Let's import a tab delimited file called `flower.txt` which contains the data we saw previously in this [Chapter](#df) and assign it to an object called `flowers`. The file is located in a `data` directory which itself is located in our [root directory](#dir_struct). The first row of the data contains the variable (column) names. To use the `read.table()` function to import this file

```{r df1, echo=TRUE, collapse=TRUE}
flowers <- read.table(file = 'data/flower.txt', header = TRUE, sep = "\t")
```

There are a few things to note about the above command. First, the file path and the filename (including the file extension) needs to be enclosed in either single or double quotes (i.e. `data/flower.txt` bit) as the `read.table()` function expects this to be a character string. If your working directory is already set to the directory which contains the file, you donâ€™t need to include the entire file path just the filename. In the example above, the file path is separated with a single forward slash `/`. This will work regardless of the operating system you are using. Windows users may be more familiar with the single backslash notation and if you want to keep using this you will need to include them as double backslashes. Note though that the double backslash notation will **not** work on computers using Mac OSX or Linux. 

```{r df2, echo=TRUE, eval=FALSE}
flowers <- read.table(file = 'C:\\Documents\\Prog1\\data\\flower.txt', header = TRUE, sep = "\t")
```

The `header = TRUE` argument specifies that the first row of your data contains the variable names (i.e. `nitrogen`, `block` etc). If this is not the case you can specify `header = FALSE` (actually, this is the default value so you can omit this argument entirely). The `sep = "\t"` argument tells R that the file delimiter is a tab (`\t`).  

After importing our data into R it doesn't appear that R has done much, at least nothing appears in the R Console! To see the contents of the data frame we could just type the name of the object as we have done previously. **BUT** before you do that, think about why you're doing this. If your data frame is anything other than tiny all you're going to do is fill up your Console with data. It's not like you can easily check whether there are any errors or that your data has been imported correctly. A much better solution is to to use our old friend the `str()` function to return a compact and informative summary of your data frame.

```{r df3, echo=TRUE, collapse=TRUE}
str(flowers) 
```

Here we see that `flowers` is a 'data.frame' object which contains 96 rows and 8 variables (columns). Each of the variables are listed along with their data class and the first 10 values. As we mentioned previously in this Chapter, it can be quite convenient to copy and paste this into your R script as a comment block for later reference. 

Notice also that R has decided that your character string variables (`treat` and `nitrogen`) should be treated as factors. If this is not what you want you can prevent this by using the `stringsAsFactors = FALSE` argument when you use the `read.table()` function.

```{r df4, echo=TRUE, collapse=TRUE}
flowers <- read.table(file = 'data/flower.txt', header = TRUE, sep = "\t", 
											stringsAsFactors = FALSE)
str(flowers) 
```

Other useful arguments include `dec =` and `na.strings =`. The `dec =` argument allows you to change the default character (`.`) used for a decimal point. This is useful if you are in a country where decimal places are usually represented by a comma (i.e. `dec = ","`). The `na.strings =` argument allows you to import data where missing values are represented with symbols other than `NA`. This can be quite common if you are importing data from other statistical software such as Minitab which represents missing values as a `*` (`na.strings = "*"`). 

R has a number of variants of the `read.table()` function that you can use to import a variety of file formats. Actually, these variants just use the `read.table()` function but include different combinations of arguments by default to help import different file types. The most useful of these are the `read.csv()`, `read.csv2()` and `read.delim()` functions. The `read.csv()` function is used to import comma separated value (.csv) files and assumes that the data in columns are separated by a comma (it sets `sep = ","` by default). It also assumes that the first row of the data contains the variable names by default (it sets `header = TRUE` by default). The `read.csv2()` function assumes data are separated by semicolons and that a comma is used instead of a decimal point (as in many mainland European countries). The `read.delim()` function is used to import tab delimited data and also assumes assumes that the first row of the data contains the variable names by default. 

```{r df5, echo=TRUE, eval=FALSE}
# import .csv file
flowers <- read.csv(file = 'data/flower.csv') 

# import .csv file with dec = "," and sep = ";"
flowers <- read.csv2(file = 'data/flower.csv') 

# import tab delim file with sep = "\t"
flowers <- read.delim(file = 'data/flower.txt') 
```

You can even import spreadsheet files from MS Excel or other statistics software directly into R but our advice is that this should generally be avoided if possible as it just adds a layer of uncertainty between you and your data. In our opinion it's almost always better to export your spreadsheets as tab or comma delimited files and then import them into R using the `read.table()` function. If you're hell bent on directly importing data from other software you will need to install the `foreign` package which has functions for importing Minitab, SPSS, Stata and SAS files or the `xlsx` package to import Excel spreadsheets. 

### Common import frustrations

It's quite common to get a bunch of really frustrating error messages when you first start importing data into R. Perhaps the most common is

```{r, eval=FALSE}
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'flower.txt': No such file or directory
```

This error message is telling you that R cannot find the file you are trying to import. It usually rears it's head for one of a couple of reasons (or all of them!). The first is that you've made a mistake in the spelling of either the filename or file path. Another common mistake is that you have forgotten to include the file extension in the filename (i.e. `.txt`). Lastly, the file is not where you say it is or you've an used an incorrect file path. Using RStudio [Projects](#rsprojs) and having a logical [directory structure](#dir_struct) goes along way to avoiding these types of errors.

Another really common mistake is to forget to include the `header = TRUE` argument when the first row of the data contains variable names. For example, if we omit this argument when we import our `flowers.txt` file everything looks OK at first (no error message at least)

```{r df6, echo=TRUE, collapse=TRUE}
flowers_bad <- read.table(file = 'data/flower.txt', sep = "\t")
```

but when we take a look at our data frame using `str()`

```{r df7, echo=TRUE, collapse=TRUE}
str(flowers_bad)
```

We can see an obvious problem, all of our variables have been imported as factors and are called `V1`, `V2`, `V3` ... `V8`. The problem happens because we haven't told the `read.table()` function that the first row contains the variable names and so it treats them as data. As soon as we have a single character string in any of our data vectors R treats the vectors as character type data (remember all elements in a vector must contain the [same type of data](#vectors)). But why are they factors rather than character strings? Well, this is because when we use the `read.table()` function any variable containing character strings are converted to factors by default (unless we use the `stringsAsFactors =` argument as above).

### Other import options

There are numerous other functions to import data from a variety of sources and formats. Most of these functions are contained in packages that you will need to install before using them. We list a couple of the more useful packages and functions below. 

The `fread()` function from the `read.table` package is great for importing large data files quickly and efficiently (much faster than the `read.table()` function). One of the great things about the `fread()` function is that it will automatically detect many of the arguments you would normally need to specify (like `sep =` etc). One of the things you will need to consider though is that the `fread()` function will return a `data.table` object not a `data.frame` as would be the case with the `read.table()` function. This is usually not a problem as you can pass a `data.table` object to any function that only accepts `data.frame` objects. To learn more about the differences between `data.table` and `data.frame` objects see [here][data-table]. 

```{r df8, echo=TRUE, eval=FALSE}
library(read.table)
all_data <- fread('data/flower.txt')
```

Various functions from the `readr` package are also very efficient at reading in large data files. The `readr` package is part of the '[tidyverse][tidyverse]' collection of packages and provides many equivalent functions to base R for importing data. The `readr` functions are used in a similar way to the `read.table()` or `read.csv()` functions and many of the arguments are the same (see `?readr::read_table` for more details). There are however some differences. For example, when using the `read_table()` function the `header = TRUE` argument is replaced by `col_names = TRUE`. Also, character class variables are not automatically converted to factors when using `read_table()` and the function returns a 'tibble' class object which is the tidyverse equivalent of a 'data.frame' object (see [here][tibbles] for differences). 

```{r df9, echo=TRUE, eval=FALSE}
library(readr)
# import white space delimited files
all_data <- read_table('data/flower.txt', col_names = TRUE)

# import comma delimited files
all_data <- read_csv('data/flower.txt')

# import tab delimited files
all_data <- read_delim('data/flower.txt', delim = "\t")

# or use
all_data <- read_tsv('data/flower.txt')
```

If your data file is ginormous, then the `ff` and `bigmemory` packages may be useful as they're both able to store large  data in a memory efficient manner. You can find out more about these functions [here][ff] and [here][bigmem].


## Wrangling data frames

## Summarising data frames

## Other data structures

### Lists

The final data structure we will consider is a list. A list is a data structure that can contain any class of variable and are invaluable for storing complicated output from functions among other things. In fact, many of Râ€™s statistical functions (see Section 5) generate lists which contain useful information which can be accessed directly (residuals and fitted values for example). 

## Exporting data

**plan**

	- `read_table` in `readr` package
	- `data.table` package - `fread` 

data wrangling using `$` and `[ ]`

positional
logical
include wide -> log and long -> wide
summarising data 
apply, tapply, by, aggregate, merge

exporting data
write.table

\  

```{r links, child="links.md"}
```

